Теория информации имеет огромное значение для развития современной науки  и  техники.  Она  получила  широкое применение в физике, микроэлектронике, а также  во  всех  отраслях  техники, где необходимо решать проблемы хранения, получения и передачи информации.

<<Предметом теории информации, как правило, являются теоремы, устанавливающие предельные возможности методов обработки и передачи сообщений. Эти предельные возможности определяются свойствами источников и каналов.
В качестве примера можно привести три типичные вопроса, ответы на которые можно найти в теории информации.

1. Допустим, что имеется статистическое описание (математическая модель) некоторого источника сообщений. Требуется определить наименьшее количество двоичных символов, которые необходимы для того, чтобы указать последовательность сообщений, порожденных источником. При этом может быть задана некоторая функция качества и требоваться указание сообщений с заданной величиной ошибки.

2. Допустим, что имеется статистическое описание (математическая модель) некоторого канала связи. Требуется определить наибольшую возможную скорость передачи по такому каналу при условии, что вероятность ошибки ограничена сверху некоторым достаточно малым числом.

3. Допустим, что заданы источник сообщений, канал связи и определена ошибка при восстановлении. Требуется определить наименьшее значение ошибки, которую можно достичь, передавая сообщения данного источника по данному каналу связи[1]>>.

В данной курсовой работе рассматривается решение задач, посвященных этим и другим важным вопросам теории информации.

<<Хотя теория информации, как правило, не дает практических рекомендаций инженерам, проектирующим аппаратуру обработки и передачи информации, она тем не менее является важным инструментом при анализе различных технических систем: телеметрических, цифровой передачи речи или телевизионных изображений, передачи данных, хранения информации, управляющих или командных и т. д. В ряде случаев в теории информации даются ответы на вопросы о предельных возможностях систем. К сожалению, готовые ответы имеются пока далеко не на все возникающие вопросы. Однако, что особенно важно, на основе теории информации инженер может правильно сформулировать свою задачу, наметить ход решений и, быть может, решить её>>~\cite{kolesnik}.

Данная курсовая работа  содержит четыре раздела, посвящённых вопросам изучения и расчёта  информационных характеристик источников сообщений, сигналов и каналов. 

Первый раздел содержит три задачи. В них производится расчёт информационных характеристик источников дискретных сообщений: энтропии, количества информации, производительности источника. 

Раздел <<Расчёт информационных характеристик дискретного канала>> содержит две задачи, в которых рассматривается двоичный симметричный канал, для которого отыскиваются апостериорные вероятности символов, определяется скорость передачи информации по каналу. 

Раздел <<Согласование дискретного источника с дискретным каналом>> демонстрирует методы эффективного кодирования на примере кода Фано, описывает возможность безошибочной передачи информации по двоичному каналу (теорема Шеннона для канала без шума). 

В последнем разделе <<Дискретизация и квантования>> рассказывается о методе дискретизации непрерывного сигнала, процессе восстановления непрерывного сигнала по дискретным отсчётам с помощью интерполирующего фильтра, параметрах квантованного сообщения. 

